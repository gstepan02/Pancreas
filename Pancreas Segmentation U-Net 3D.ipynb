{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWDaAsbqNNVR",
        "metadata": {},
        "outputId": "daf7eacb-d6e7-4fc7-94a9-93aad8270e6a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "## If you want to select specific video device\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from scipy import stats\n",
        "import scipy.ndimage\n",
        "from scipy.ndimage import label, generate_binary_structure\n",
        "from scipy.ndimage.measurements import sum as nd_sum\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seeds\n",
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8k0Y4t1lnty",
        "outputId": "682928d7-7de0-4fbb-806c-90ded1630ae4"
      },
      "outputs": [],
      "source": [
        "# Connect to Google Drive (optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_OEznWqmiqAU",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Enter the path to the dataset\n",
        "folder = 'D:/Task07_Pancreas/'\n",
        "imagesTr = folder + 'imagesTr/' \n",
        "labelsTr = folder + 'labelsTr/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrgN_ojTXmev",
        "metadata": {},
        "outputId": "09769083-ac26-4c06-823a-3e1459e8a3e3"
      },
      "outputs": [],
      "source": [
        "# Function to return the list of paths to dataset files\n",
        "def get_file_paths(data):\n",
        "    file_paths = []\n",
        "    for root, directories, files in os.walk(data):\n",
        "        for filename in files:\n",
        "            file_paths.append(os.path.join(root, filename))\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ct_paths len: 232\n",
            "label_paths len: 232\n"
          ]
        }
      ],
      "source": [
        "# Get the paths of CT files and the masks to variables\n",
        "ct_paths = sorted(get_file_paths(imagesTr))\n",
        "label_paths = sorted(get_file_paths(labelsTr))\n",
        "print(f'ct_paths len: {len(ct_paths)}')\n",
        "print(f'label_paths len: {len(label_paths)}')\n",
        "# for file_path in  label_paths:\n",
        "#     print(file_path)\n",
        "\n",
        "for i in range(len(ct_paths)):\n",
        "    if ct_paths[i][-20:-7] != label_paths[i][-20:-7]:\n",
        "        print(f'Error in {ct_paths[i][-20:-7]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 185\n",
            "Testing set size: 47\n"
          ]
        }
      ],
      "source": [
        "# Fix the files indexes for training and testing sets\n",
        "indexes = list(range(len(ct_paths)))\n",
        "random.shuffle(indexes)\n",
        "split_index = int(0.8 * len(indexes))\n",
        "train_indexes = indexes[:split_index]\n",
        "test_indexes = indexes[split_index:]\n",
        "\n",
        "ct_paths_train = [ct_paths[i] for i in train_indexes]\n",
        "label_paths_train = [label_paths[i] for i in train_indexes]\n",
        "ct_paths_test = [ct_paths[i] for i in test_indexes]\n",
        "label_paths_test = [label_paths[i] for i in test_indexes]\n",
        "print(\"Training set size:\", len(ct_paths_train))\n",
        "print(\"Testing set size:\", len(ct_paths_test))\n",
        "for i in range(len(ct_paths_train)):\n",
        "    if ct_paths_train[i][-20:-7] != label_paths_train[i][-20:-7]:\n",
        "        print(f'Error in {ct_paths_train[i][-20:-7]}')\n",
        "for i in range(len(ct_paths_test)):\n",
        "    if ct_paths_test[i][-20:-7] != label_paths_test[i][-20:-7]:\n",
        "        print(f'Error in {ct_paths_test[i][-20:-7]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpmnY4khkUw-",
        "metadata": {},
        "outputId": "ac36a0a9-6fa4-49c8-f4f6-013932764b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainloader size with batch size = 1: 185\n",
            "Testloader size with batch size = 1: 47\n"
          ]
        }
      ],
      "source": [
        "# Pancreas data generator class\n",
        "class PancreasDataset():\n",
        "    def __init__(self, ct_paths, label_paths, transform):\n",
        "        self.ct_paths = ct_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ct_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ct_path = self.ct_paths[idx]\n",
        "        label_path = self.label_paths[idx]\n",
        "\n",
        "        ct_image = nib.load(ct_path)\n",
        "        ct_image = ct_image.get_fdata()\n",
        "\n",
        "        label_image = nib.load(label_path)\n",
        "        label_image = label_image.get_fdata()\n",
        "\n",
        "        label_image[label_image == 2] = 1\n",
        "\n",
        "        zoom_factors = (128 / ct_image.shape[0], 128 / ct_image.shape[1], 64 / ct_image.shape[2])\n",
        "        ct_image = scipy.ndimage.zoom(ct_image, zoom_factors, order=1)\n",
        "        label_image = scipy.ndimage.zoom(label_image, zoom_factors, order=0)\n",
        "        \n",
        "        min_value = np.min(ct_image)\n",
        "        max_value = np.max(ct_image)\n",
        "        ct_image = (ct_image - min_value) / (max_value - min_value)\n",
        "\n",
        "        ct_image = self.transform(ct_image.astype(np.float32))\n",
        "        label_image = self.transform(label_image.astype(np.float32))\n",
        "\n",
        "        return {'ct': ct_image, 'label': label_image}\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.unsqueeze(0)),  # Add a channel dimension\n",
        "])\n",
        "\n",
        "train_dataset = PancreasDataset(ct_paths_train, label_paths_train, transform)\n",
        "test_dataset = PancreasDataset(ct_paths_test, label_paths_test, transform)\n",
        "\n",
        "# Enter the batch size\n",
        "batch_size = 1\n",
        "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f'Trainloader size with batch size = {batch_size}: {len(trainloader)}')\n",
        "print(f'Testloader size with batch size = {batch_size}: {len(testloader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq13fpQqkUw-",
        "metadata": {},
        "outputId": "d250b2c5-533c-44bf-c7ff-195efd2f3040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values: tensor([0., 1.])\n",
            "Minimum value in test slices: 0.0\n",
            "Maximum value in test slices: 1.0\n",
            "Batch CT slices shape: torch.Size([1, 1, 64, 128, 128])\n",
            "Batch Label slices shape: torch.Size([1, 1, 64, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Just to check the tensor\n",
        "for batch in trainloader:\n",
        "    ct_images = batch['ct']\n",
        "    label_images = batch['label']\n",
        "\n",
        "    test = label_images\n",
        "    # print({test})\n",
        "\n",
        "    print(f'Unique values: {torch.unique(test)}')\n",
        "    print(f'Minimum value in test slices: {torch.min(test)}')\n",
        "    print(f'Maximum value in test slices: {torch.max(test)}')\n",
        "\n",
        "    print(f'Batch CT slices shape: {ct_images.shape}')\n",
        "    print(f'Batch Label slices shape: {label_images.shape}')\n",
        "\n",
        "    ct_slices_1 = ct_images[0].squeeze().numpy().squeeze()\n",
        "    label_slices_1 = label_images[0].squeeze().numpy().squeeze()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxfBaW-Gdpya",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Just to visualize the tensor\n",
        "for i in range(ct_slices_1.shape[0]):\n",
        "    ar = ct_slices_1[i,:,:]\n",
        "    ar_lbl = label_slices_1[i,:,:]\n",
        "    fig = plt.figure(figsize=(8,5))\n",
        "\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(ar)\n",
        "    plt.title('Abdominal CT')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(ar_lbl)\n",
        "    plt.title('Pancreas Mask')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1fHhhgQnqVZl"
      },
      "outputs": [],
      "source": [
        "# U-Net 3D structure\n",
        "class DoubleConv3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv3D, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.encoder1 = DoubleConv3D(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = DoubleConv3D(64, 128)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = DoubleConv3D(128, 256)\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = DoubleConv3D(256, 512)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)\n",
        "        self.decoder3 = DoubleConv3D(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
        "        self.decoder2 = DoubleConv3D(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder1 = DoubleConv3D(128, 64)\n",
        "\n",
        "        self.final_conv = nn.Conv3d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc1_pool = self.pool1(enc1)\n",
        "        enc2 = self.encoder2(enc1_pool)\n",
        "        enc2_pool = self.pool2(enc2)\n",
        "        enc3 = self.encoder3(enc2_pool)\n",
        "        enc3_pool = self.pool3(enc3)\n",
        "\n",
        "        bottleneck = self.bottleneck(enc3_pool)\n",
        "\n",
        "        dec3 = self.upconv3(bottleneck)\n",
        "        dec3 = torch.cat([enc3, dec3], dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat([enc2, dec2], dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat([enc1, dec1], dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "\n",
        "        output = self.final_conv(dec1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY-NE50FMkcA",
        "outputId": "ae24f1f5-d54d-4805-a506-e0712729dcc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 64, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Just to check that U-Net is running correctly\n",
        "in_channels = 1\n",
        "out_channels = 1\n",
        "model = UNet3D(in_channels, out_channels).to(device)\n",
        "\n",
        "# Enter desired tensor shape\n",
        "input_data = torch.randn(1, 1, 64, 128, 128).to(device)\n",
        "output_data = model(input_data)\n",
        "print(output_data.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear the memory\n",
        "del input_data\n",
        "del output_data\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_allocated()/1024**2)\n",
        "print(torch.cuda.memory_cached()/1024**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zs2SagFoXat"
      },
      "outputs": [],
      "source": [
        "# Model initialization\n",
        "model = UNet3D(1,1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Initializing lists for storing loss data\n",
        "train_avg_losses = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch in trainloader:\n",
        "        ct_images = batch['ct'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        labels = labels\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(ct_images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_loss /= len(trainloader)\n",
        "    train_avg_losses.append(train_loss)\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    # Testing\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            ct_images_test = batch['ct'].to(device)\n",
        "            labels_test = batch['label'].to(device)\n",
        "            labels_test = labels_test\n",
        "\n",
        "            outputs_test = model(ct_images_test)\n",
        "            test_loss += criterion(outputs_test, labels_test).item()\n",
        "\n",
        "    # Saving loss data\n",
        "    test_loss /= len(testloader)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    # Saving the best model\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        # Enter the path for saving the model\n",
        "        torch.save(model.state_dict(), 'D:/Task07_Pancreas/best_model.pth')\n",
        "\n",
        "    # Training progress\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Last Loss: {loss.item():.4f}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "uaUXzTQFtkTX",
        "outputId": "ef728c0c-9b1f-4602-eb8d-cd5a87280834"
      },
      "outputs": [],
      "source": [
        "# Loss function change chart\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_avg_losses, label='Train Loss', color='blue')\n",
        "plt.plot(train_losses, label='Train Last Loss', linestyle='dashed', color='blue')\n",
        "\n",
        "plt.plot(test_losses, label='Test Loss', color='red')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Loss Over Time')\n",
        "plt.legend()\n",
        "plt.ylim(0, 0.2)\n",
        "# plt.xlim(0, 150)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UNet3D(\n",
              "  (encoder1): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder2): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder3): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bottleneck): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (upconv3): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (decoder3): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (upconv2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (decoder2): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (upconv1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (decoder1): DoubleConv3D(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (final_conv): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load saved model\n",
        "model = UNet3D(1,1)\n",
        "# Enter the path to the saved model\n",
        "model.load_state_dict(torch.load('D:/Task07_Pancreas/best_model.pth'))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = []\n",
        "n = 0\n",
        "for batch in testloader:\n",
        "    ct_images = batch['ct'].to(device)\n",
        "    labels = batch['label'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(ct_images)\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        for i in range(ct_images.shape[0]):\n",
        "            filename = ct_paths[n][-19:-7]\n",
        "            n += 1\n",
        "            ct_images_np = ct_images[i].squeeze().cpu().numpy().squeeze()\n",
        "            outputs_np = outputs[i].squeeze().cpu().numpy().squeeze()\n",
        "            labels_np = labels[i].squeeze().cpu().numpy().squeeze()\n",
        "            mean_value = 0.492\n",
        "            outputs_np = (outputs_np > mean_value)\n",
        "            outputs_np_float = outputs_np.astype(float)\n",
        "\n",
        "            ## Code block for isolating the largest 3D object in the array\n",
        "            # structure = generate_binary_structure(3, 1)  # Define the structure for determining connected components\n",
        "            # labeled_array, num_features = label(outputs_np, structure)\n",
        "            # component_sizes = nd_sum(outputs_np, labeled_array, range(1, num_features + 1))\n",
        "            # largest_component_index = np.argmax(component_sizes) + 1\n",
        "            # largest_component = np.zeros_like(outputs_np)\n",
        "            # largest_component[labeled_array == largest_component_index] = 1\n",
        "            # outputs_np = largest_component\n",
        "\n",
        "            # IoU (Jaccard Index)\n",
        "            intersection = np.sum((labels_np == 1) & (outputs_np == 1))\n",
        "            union = np.sum((labels_np == 1) | (outputs_np == 1))\n",
        "            iou = intersection / union\n",
        "            \n",
        "            # Dice Coefficient (F1 Score)\n",
        "            dice = 2 * np.sum((labels_np == 1) & (outputs_np == 1)) / (np.sum(labels_np == 1) + np.sum(outputs_np == 1))\n",
        "\n",
        "            # # Code block for visualizing the work of the model\n",
        "            # print(filename)\n",
        "            # print(iou)\n",
        "            # print(dice)\n",
        "            # if dice >= 0.85:\n",
        "            #     for i in range(ct_images_np.shape[0]):\n",
        "            #         ar = ct_images_np[i,:,:]\n",
        "            #         ar_lbl = labels_np[i,:,:]\n",
        "            #         ar_out = outputs_np[i,:,:]\n",
        "            #         if np.sum(ar_lbl) > 0: # to show only slices with pancreas\n",
        "            #             fig = plt.figure(figsize=(18,15))\n",
        "\n",
        "            #             plt.subplot(1,3,1)\n",
        "            #             plt.imshow(ar)\n",
        "\n",
        "            #             plt.subplot(1,3,2)\n",
        "            #             plt.imshow(ar_lbl)\n",
        "\n",
        "            #             plt.subplot(1,3,3)\n",
        "            #             plt.imshow(ar_out)\n",
        "\n",
        "            #             plt.show()\n",
        "            # print()\n",
        "\n",
        "            data.append([filename, iou, dice])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Filename', 'IoU', 'Dice'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean IoU value: 0.6957 ± 0.0372\n",
            "Mean Dice value: 0.8136 ± 0.0281\n",
            "Median IoU value: 0.7491\n",
            "Median Dice value: 0.8565\n"
          ]
        }
      ],
      "source": [
        "# Statistics\n",
        "# Calculating mean and median for the IoU and Dice\n",
        "iou_mean = df['IoU'].mean()\n",
        "dice_mean = df['Dice'].mean()\n",
        "iou_median = df['IoU'].median()\n",
        "dice_median = df['Dice'].median()\n",
        "\n",
        "n = len(df)\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Calculating the standard deviation for the IoU and Dice\n",
        "iou_std = df['IoU'].std()\n",
        "dice_std = df['Dice'].std()\n",
        "\n",
        "# Calculating the standard error for the IoU and Dice\n",
        "iou_stderr = iou_std / (n**0.5)\n",
        "dice_stderr = dice_std / (n**0.5)\n",
        "\n",
        "# Calculating T-value for the given confidence level\n",
        "t_value = stats.t.ppf((1 + confidence_level) / 2, n - 1)\n",
        "\n",
        "# Calculating the margin of error for the IoU and Dice\n",
        "iou_margin_error = t_value * iou_stderr\n",
        "dice_margin_error = t_value * dice_stderr\n",
        "\n",
        "print(f\"Mean IoU value: {iou_mean:.4f} ± {iou_margin_error:.4f}\")\n",
        "print(f\"Mean Dice value: {dice_mean:.4f} ± {dice_margin_error:.4f}\")\n",
        "\n",
        "print(f\"Median IoU value: {iou_median:.4f}\")\n",
        "print(f\"Median Dice value: {dice_median:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
